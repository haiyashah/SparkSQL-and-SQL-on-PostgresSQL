{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e1d58c70-7090-4c5d-a70c-e4353f689003",
      "metadata": {
        "id": "e1d58c70-7090-4c5d-a70c-e4353f689003"
      },
      "source": [
        "# Homework 2: Question 4 - Extending the table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b099e28-7633-4cf8-a24a-8511175892d2",
      "metadata": {
        "id": "5b099e28-7633-4cf8-a24a-8511175892d2"
      },
      "source": [
        "Haiya Niraj Shah \\\n",
        "Andrew id - haiyas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prerequisities from previous questions"
      ],
      "metadata": {
        "id": "EkfJt60UPab8"
      },
      "id": "EkfJt60UPab8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c7d4d1-2d37-432c-ac34-348e1da06eff",
      "metadata": {
        "id": "59c7d4d1-2d37-432c-ac34-348e1da06eff"
      },
      "outputs": [],
      "source": [
        "#Setup Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SQLContext\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "conf=pyspark.SparkConf().set('spark.driver.host','127.0.0.1').setAppName(\"NewsData\").setMaster(\"local\")\n",
        "sc=SparkContext.getOrCreate(conf=conf)\n",
        "sqlContext=SQLContext(sc)\n",
        "spark=sqlContext.sparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Database configuration\n",
        "db_config ={\n",
        "    'username':\"postgres\",\n",
        "    'password':\"password\",\n",
        "    'url':\"jdbc:postgresql://localhost:5432/postgres\",\n",
        "    'table':\"news.google_newsFeed\",\n",
        "    'driver':\"org.postgresql.Driver\"}"
      ],
      "metadata": {
        "id": "FKsP7LE-EN8g"
      },
      "id": "FKsP7LE-EN8g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fetching data\n",
        "rss_url= \"https://news.google.com/rss/search?q=technology&hl=en-US&gl=US&ceid=US:en\"\n",
        "response =requests.get(rss_url)\n",
        "xml_data =response.content"
      ],
      "metadata": {
        "id": "CLGctHdQEX_S"
      },
      "id": "CLGctHdQEX_S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059ec735-b86e-4f23-948d-f1daa90215d0",
      "metadata": {
        "id": "059ec735-b86e-4f23-948d-f1daa90215d0",
        "outputId": "05bb8214-47c4-4991-9f09-c8d6bec35ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed 100 news items\n"
          ]
        }
      ],
      "source": [
        "#Standard date conversion\n",
        "from datetime import datetime\n",
        "root=ET.fromstring(xml_data)\n",
        "\n",
        "channel=root.find('channel')\n",
        "build_date_str=channel.find('lastBuildDate').text if channel.find('lastBuildDate') is not None else None\n",
        "\n",
        "build_date=None\n",
        "if build_date_str:\n",
        "    try:\n",
        "        build_date=datetime.strptime(build_date_str, '%a, %d %b %Y %H:%M:%S %Z')\n",
        "    except:\n",
        "        build_date=None\n",
        "\n",
        "#Extract news\n",
        "news_data=[]\n",
        "for item in root.findall('.//item'):\n",
        "    title=item.find('title')\n",
        "    link=item.find('link')\n",
        "    pub_date=item.find('pubDate')\n",
        "    desc=item.find('description')\n",
        "    source=item.find('source')\n",
        "\n",
        "    pub_date_converted=None\n",
        "    if pub_date is not None and pub_date.text:\n",
        "        try:\n",
        "            pub_date_converted=datetime.strptime(pub_date.text, '%a, %d %b %Y %H:%M:%S %Z')\n",
        "        except:\n",
        "            pub_date_converted=None\n",
        "\n",
        "    source_text=source.text if source is not None else None\n",
        "\n",
        "    news_item={\n",
        "        'lastBuildDate':build_date,\n",
        "        'title':title.text if title is not None else None,\n",
        "        'link':link.text if link is not None else None,\n",
        "        'pubDate':pub_date_converted,\n",
        "        'description':desc.text if desc is not None else None,\n",
        "        'source':source_text\n",
        "    }\n",
        "\n",
        "    news_data.append(news_item)\n",
        "\n",
        "print(f\"Parsed {len(news_data)} news items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "137e6029-8160-472e-af84-249279519ece",
      "metadata": {
        "id": "137e6029-8160-472e-af84-249279519ece",
        "outputId": "49d18b03-91d8-4313-c964-eca65d7dd65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------------------+--------------------+-------------------+------------------+--------------------+\n",
            "|         description|      lastBuildDate|                link|            pubDate|            source|               title|\n",
            "+--------------------+-------------------+--------------------+-------------------+------------------+--------------------+\n",
            "|<a href=\"https://...|2025-09-18 17:42:32|https://news.goog...|2025-09-18 13:05:56|            GOV.UK|Memorandum of Und...|\n",
            "|<a href=\"https://...|2025-09-18 17:42:32|https://news.goog...|2025-09-17 13:37:37|      Fox Business|Expert predicts A...|\n",
            "|<a href=\"https://...|2025-09-18 17:42:32|https://news.goog...|2025-09-18 16:57:47|The Times of India|New technology la...|\n",
            "+--------------------+-------------------+--------------------+-------------------+------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "Inserted 100 records\n"
          ]
        }
      ],
      "source": [
        "#Inserting data\n",
        "df = spark.createDataFrame(news_data)\n",
        "df.show(3, truncate=True)\n",
        "\n",
        "df.write.format(\"jdbc\")\\\n",
        ".mode(\"overwrite\")\\\n",
        ".option(\"url\",db_config['url'])\\\n",
        ".option(\"dbtable\",db_config['table'])\\\n",
        ".option(\"user\",db_config['username'])\\\n",
        ".option(\"password\",db_config['password'])\\\n",
        ".option(\"driver\",db_config['driver'])\\\n",
        ".save()\n",
        "\n",
        "print(f\"Inserted {df.count()} records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a896286-1d71-4e29-8eb1-6832a8405133",
      "metadata": {
        "id": "5a896286-1d71-4e29-8eb1-6832a8405133"
      },
      "source": [
        "#You decided to extend your table to include non-technology related news as well. Update your table to add a new column called “category” and\n",
        "- pre-populate it with the value of “technology” for existing records. Then, populate the table with the following feeds:\n",
        "- Business: https://news.google.com/rss/search?q=business&hl=en\n",
        "US&gl=US&ceid=US:en\n",
        "Use category value of “business” for these news records.\n",
        "- Sports: https://news.google.com/rss/search?q=sports&hl=en\n",
        "US&gl=US&ceid=US:en  \n",
        "Use category value of “sports” for these news records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35a9a8b-bbdd-4554-b61e-4a6cff2b79be",
      "metadata": {
        "id": "f35a9a8b-bbdd-4554-b61e-4a6cff2b79be"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import lit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268249b3-a170-41d6-905a-66044ccbd9e6",
      "metadata": {
        "id": "268249b3-a170-41d6-905a-66044ccbd9e6"
      },
      "outputs": [],
      "source": [
        "existing_df=spark.read.format(\"jdbc\")\\\n",
        "    .option(\"url\",db_config['url'])\\\n",
        "    .option(\"dbtable\",db_config['table'])\\\n",
        "    .option(\"user\",db_config['username'])\\\n",
        "    .option(\"password\",db_config['password'])\\\n",
        "    .option(\"driver\",db_config['driver'])\\\n",
        "    .load()\\\n",
        "    .cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61034ddc-7862-4945-90b9-c18885821bdb",
      "metadata": {
        "id": "61034ddc-7862-4945-90b9-c18885821bdb",
        "outputId": "bc491bc9-8af1-4b70-da4f-2b28091242e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Existing records with category added: 100\n"
          ]
        }
      ],
      "source": [
        "#Technology added\n",
        "existing_with_category=existing_df.withColumn(\"category\",lit(\"technology\"))\n",
        "print(f\"Existing records with category added: {existing_with_category.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7404ec32-529f-456f-b70b-292a1724950b",
      "metadata": {
        "id": "7404ec32-529f-456f-b70b-292a1724950b"
      },
      "outputs": [],
      "source": [
        "existing_with_category.write.format(\"jdbc\")\\\n",
        "    .option(\"url\",db_config['url'])\\\n",
        "    .option(\"dbtable\",db_config['table'])\\\n",
        "    .option(\"user\",db_config['username'])\\\n",
        "    .option(\"password\",db_config['password'])\\\n",
        "    .option(\"driver\",db_config['driver'])\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f218e7e-a322-4020-9c1c-a0fed9bc49a8",
      "metadata": {
        "id": "9f218e7e-a322-4020-9c1c-a0fed9bc49a8"
      },
      "outputs": [],
      "source": [
        "def add_news_with_category(feed_url, category_name):\n",
        "    response=requests.get(feed_url)\n",
        "    xml_data=response.content\n",
        "    root=ET.fromstring(xml_data)\n",
        "\n",
        "    channel=root.find('channel')\n",
        "    build_date_str=channel.find('lastBuildDate').text if channel.find('lastBuildDate') is not None else None\n",
        "    build_date=None\n",
        "    if build_date_str:\n",
        "        try:\n",
        "            build_date = datetime.strptime(build_date_str, '%a, %d %b %Y %H:%M:%S %Z')\n",
        "        except:\n",
        "            build_date = None\n",
        "\n",
        "    #Same as Q2 but with category\n",
        "    news_data=[]\n",
        "    for item in root.findall('.//item'):\n",
        "        title=item.find('title')\n",
        "        link=item.find('link')\n",
        "        pub_date=item.find('pubDate')\n",
        "        desc=item.find('description')\n",
        "        source =item.find('source')\n",
        "\n",
        "        pub_date_converted = None\n",
        "        if pub_date is not None and pub_date.text:\n",
        "            try:\n",
        "                pub_date_converted = datetime.strptime(pub_date.text, '%a, %d %b %Y %H:%M:%S %Z')\n",
        "            except:\n",
        "                pub_date_converted = None\n",
        "\n",
        "        source_text=source.text if source is not None else None\n",
        "\n",
        "        news_item={\n",
        "            'lastBuildDate': build_date,\n",
        "            'title':title.text if title is not None else None,\n",
        "            'link': link.text if link is not None else None,\n",
        "            'pubDate':pub_date_converted,\n",
        "            'description': desc.text if desc is not None else None,\n",
        "            'source':source_text,\n",
        "            'category':category_name\n",
        "        }\n",
        "        news_data.append(news_item)\n",
        "\n",
        "    df=spark.createDataFrame(news_data)\n",
        "    df.write.format(\"jdbc\")\\\n",
        "        .option(\"url\",db_config['url'])\\\n",
        "        .option(\"dbtable\",db_config['table'])\\\n",
        "        .option(\"user\",db_config['username'])\\\n",
        "        .option(\"password\",db_config['password'])\\\n",
        "        .option(\"driver\",db_config['driver'])\\\n",
        "        .mode(\"append\")\\\n",
        "        .save()\n",
        "\n",
        "    print(f\"Added {df.count()} {category_name} articles\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "352632fa-d877-42c8-8e25-a98a5c1b9839",
      "metadata": {
        "id": "352632fa-d877-42c8-8e25-a98a5c1b9839",
        "outputId": "a6767769-5397-4d2d-a2be-ae95e3b2da63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 102 business articles\n",
            "Added 100 sports articles\n"
          ]
        }
      ],
      "source": [
        "business_url=\"https://news.google.com/rss/search?q=business&hl=en-US&gl=US&ceid=US:en\"\n",
        "sports_url=\"https://news.google.com/rss/search?q=sports&hl=en-US&gl=US&ceid=US:en\"\n",
        "add_news_with_category(business_url, \"business\")\n",
        "add_news_with_category(sports_url, \"sports\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8bcb74-dd47-444d-8027-222fadc0f95a",
      "metadata": {
        "id": "cd8bcb74-dd47-444d-8027-222fadc0f95a"
      },
      "outputs": [],
      "source": [
        "final_df=spark.read.format(\"jdbc\")\\\n",
        "    .option(\"url\",db_config['url'])\\\n",
        "    .option(\"dbtable\",db_config['table'])\\\n",
        "    .option(\"user\",db_config['username'])\\\n",
        "    .option(\"password\",db_config['password'])\\\n",
        "    .option(\"driver\",db_config['driver'])\\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290bdd17-e6f2-4bf2-ad3a-0cab0495bb0e",
      "metadata": {
        "id": "290bdd17-e6f2-4bf2-ad3a-0cab0495bb0e"
      },
      "outputs": [],
      "source": [
        "final_df.createOrReplaceTempView(\"news_table\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3bbce7-0f5d-43fe-839d-1172eac1d370",
      "metadata": {
        "id": "3e3bbce7-0f5d-43fe-839d-1172eac1d370"
      },
      "outputs": [],
      "source": [
        "distinct_categories = spark.sql(\"\"\"\n",
        "    SELECT category, COUNT(*) as count\n",
        "    FROM news_table\n",
        "    GROUP BY category\n",
        "    ORDER BY category\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2de23b2-5331-4ace-92e5-a86a77b9a1d7",
      "metadata": {
        "id": "f2de23b2-5331-4ace-92e5-a86a77b9a1d7",
        "outputId": "7f748410-165a-47f5-e80a-586589b1457d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distinct categories in database:\n",
            "+----------+-----+\n",
            "|  category|count|\n",
            "+----------+-----+\n",
            "|  business|  102|\n",
            "|    sports|  100|\n",
            "|technology|  100|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Distinct categories in database:\")\n",
        "distinct_categories.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3e024e-809b-4eb7-9c0c-0b4b550068af",
      "metadata": {
        "id": "0b3e024e-809b-4eb7-9c0c-0b4b550068af"
      },
      "source": [
        "The notebook displays the categories from the database as a way to verify the output, confirming that the \"technology,\" \"business,\" and \"sports\" categories have been successfully populated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4d5450-2c6b-4e72-8034-ee106831f252",
      "metadata": {
        "id": "6b4d5450-2c6b-4e72-8034-ee106831f252"
      },
      "source": [
        "### References\n",
        "\n",
        "### Stack Overflow Solutions\n",
        "- Spark DataFrame write to JDBC with mode overwrite creates empty table: https://stackoverflow.com/questions/45775495/spark-dataframe-write-to-jdbc-with-mode-overwrite-creates-empty-table\n",
        "- RSS feed parsing with Python xml.etree: https://stackoverflow.com/questions/1912434/how-do-i-parse-xml-in-python\n",
        "\n",
        "### Class Materials\n",
        "- Lecture_2_Introduction_to_Cloud_And_Spark on scalable data processing with PySpark DataFrames\n",
        "- Lecture_3_SQL_and_SparkSQL for data manipulation operations\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
